{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeismicReduction import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader, beta=1, recon_loss_method='mse'):\n",
    "    \"\"\"\n",
    "    Trains a single epoch of the vae model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int\n",
    "        epoch number being trained\n",
    "    model : torch.nn.module\n",
    "        model being trained, here a vae\n",
    "    optimizer : torch.optim\n",
    "        optmizer used to train model\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        data loader used for training\n",
    "    beta : float\n",
    "        beta parameter for the beta-vae\n",
    "    recon_loss_method : str\n",
    "        specifies the reconstruction loss technique\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trains the model and returns training loss for the epoch\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar, _ = model(data)\n",
    "        loss = loss_function(recon_batch,\n",
    "                             data,\n",
    "                             mu,\n",
    "                             logvar,\n",
    "                             window_size=data.shape[-1],\n",
    "                             beta=beta,\n",
    "                             recon_loss_method=recon_loss_method)\n",
    "        # print('batch:', batch_idx, 'loss:', loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # 'loss' is the SUM of all vector to vector losses in batch\n",
    "        train_loss += loss.item()  # * data.size(0)  # originally\n",
    "\n",
    "#         print('batch:', batch_idx, 'to add to total:', loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    # print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss), len(train_loader.dataset))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     4,
     8,
     105
    ]
   },
   "outputs": [],
   "source": [
    "class VaeModel(ModelAgent):\n",
    "    \"\"\"\n",
    "    Runs the VAE model to reduce the seismic data to an arbitrary sized dimension, visualised in 2 via UMAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.name = 'VAE'\n",
    "\n",
    "    def create_dataloader(self, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create pytorch data loaders for use in vae training, testing and running.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of data loader batches.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies object data loader attributes.\n",
    "\n",
    "        \"\"\"\n",
    "        # create torch tensor\n",
    "        assert self.input.shape[1] == 2, 'Expected a three dimensional input with 2 channels'\n",
    "        X = torch.from_numpy(self.input).float()\n",
    "\n",
    "        # Create a stacked representation and a zero tensor so we can use the standard Pytorch TensorDataset\n",
    "        y = torch.from_numpy(np.zeros((X.shape[0], 1))).float()\n",
    "\n",
    "        split = ShuffleSplit(n_splits=1, test_size=0.5)\n",
    "        for train_index, test_index in split.split(X):\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        train_dset = TensorDataset(X_train, y_train)\n",
    "        test_dset = TensorDataset(X_test, y_test)\n",
    "        all_dset = TensorDataset(X, y)\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        **kwargs)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=False,\n",
    "                                                       **kwargs)\n",
    "        self.all_loader = torch.utils.data.DataLoader(all_dset,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=False,\n",
    "                                                      **kwargs)\n",
    "\n",
    "    def train_vae(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse'):\n",
    "        \"\"\"\n",
    "        Handles the training of the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of complete passes over the whole training set.\n",
    "        hidden_size : int\n",
    "            Size of the latent space of the vae.\n",
    "        lr : float.\n",
    "            Learning rate for the vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        set_seed(42)  # Set the random seed\n",
    "        self.model = VAE(hidden_size,\n",
    "                         self.input.shape)  # Inititalize the model\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=lr,\n",
    "                               betas=(0.9, 0.999))\n",
    "    \n",
    "\n",
    "\n",
    "        if self.plot_loss:\n",
    "            liveloss = PlotLosses()\n",
    "            liveloss.skip_first = 0\n",
    "            liveloss.figsize = (16, 10)\n",
    "\n",
    "        # Start training loop\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            tl = train(epoch,\n",
    "                       self.model,\n",
    "                       optimizer,\n",
    "                       self.train_loader,\n",
    "                       recon_loss_method=recon_loss_method)  # Train model on train dataset\n",
    "            testl = test(epoch, self.model, self.test_loader, recon_loss_method=recon_loss_method)\n",
    "\n",
    "            if self.plot_loss:  # log train and test losses for dynamic plot\n",
    "                logs = {}\n",
    "                logs['' + 'ELBO'] = tl\n",
    "                logs['val_' + 'ELBO'] = testl\n",
    "                liveloss.update(logs)\n",
    "                liveloss.draw()\n",
    "                \n",
    "        return testl\n",
    "\n",
    "    def run_vae(self):\n",
    "        \"\"\"\n",
    "        Run the full data set through the trained vae model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies the zs attribute, an array of shape (number_traces, latent_space)\n",
    "        \"\"\"\n",
    "        _, zs = forward_all(self.model, self.all_loader)\n",
    "        return zs.numpy()\n",
    "\n",
    "    def reduce(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse', plot_loss=True):\n",
    "        \"\"\"\n",
    "        Controller function for the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs to run vae model.\n",
    "        hidden_size : int\n",
    "            Size of the vae model latent space representation.\n",
    "        lr : float\n",
    "            Learning rate for vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "        plot_loss : bool\n",
    "            Control on whether to plot the loss on vae training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies embedding attribute via generation of the low dimensional representation.\n",
    "\n",
    "        \"\"\"\n",
    "        if hidden_size < 2:\n",
    "            raise Exception('Please use hidden size > 1')\n",
    "\n",
    "        self.plot_loss = plot_loss  # define whether to plot training losses or not\n",
    "        self.create_dataloader()\n",
    "\n",
    "        if not self.loaded_model:\n",
    "            loss = self.train_vae(epochs=epochs, hidden_size=hidden_size, lr=lr, recon_loss_method=recon_loss_method)\n",
    "\n",
    "        self.embedding = self.run_vae()  # arbitrary dimension output from VAE\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     101
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_pi2 = open('./pickled/data.pickle', 'rb')\n",
    "dataholder = pickle.load(file_pi2)\n",
    "file_pi2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor has created an output with shape:  (25351, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "### Processor\n",
    "processor = Processor(dataholder)\n",
    "input1 = processor(flatten=[True, 12, 52], normalise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelAgent initialised\n"
     ]
    }
   ],
   "source": [
    "vae = VaeModel(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions tested: [4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim 4 loss 107.41001542519605\n",
      "dim 6 loss 127.12995680005214\n",
      "dim 8 loss 104.45352161295521\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "embeddings = []\n",
    "latent_dims = [i for i in range(4,36,2)]\n",
    "print('dimensions tested:', latent_dims)\n",
    "for i in latent_dims:\n",
    "    loss = vae.reduce(epochs=30, hidden_size=i, lr=0.01, plot_loss=False)\n",
    "    print('dim', i, 'loss', loss)\n",
    "    embeddings.append(vae.embedding)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(latent_dims, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
