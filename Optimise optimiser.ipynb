{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeismicReduction import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader, beta=1, recon_loss_method='mse'):\n",
    "    \"\"\"\n",
    "    Trains a single epoch of the vae model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int\n",
    "        epoch number being trained\n",
    "    model : torch.nn.module\n",
    "        model being trained, here a vae\n",
    "    optimizer : torch.optim\n",
    "        optmizer used to train model\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        data loader used for training\n",
    "    beta : float\n",
    "        beta parameter for the beta-vae\n",
    "    recon_loss_method : str\n",
    "        specifies the reconstruction loss technique\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trains the model and returns training loss for the epoch\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar, _ = model(data)\n",
    "        loss = loss_function(recon_batch,\n",
    "                             data,\n",
    "                             mu,\n",
    "                             logvar,\n",
    "                             window_size=data.shape[-1],\n",
    "                             beta=beta,\n",
    "                             recon_loss_method=recon_loss_method)\n",
    "        # print('batch:', batch_idx, 'loss:', loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # 'loss' is the SUM of all vector to vector losses in batch\n",
    "        train_loss += loss.item()  # * data.size(0)  # originally\n",
    "\n",
    "#         print('batch:', batch_idx, 'to add to total:', loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    # print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss), len(train_loader.dataset))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     104
    ]
   },
   "outputs": [],
   "source": [
    "class VaeModelADAM(ModelAgent):\n",
    "    \"\"\"\n",
    "    Runs the VAE model to reduce the seismic data to an arbitrary sized dimension, visualised in 2 via UMAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.name = 'VAE'\n",
    "\n",
    "    def create_dataloader(self, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create pytorch data loaders for use in vae training, testing and running.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of data loader batches.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies object data loader attributes.\n",
    "\n",
    "        \"\"\"\n",
    "        # create torch tensor\n",
    "        assert self.input.shape[1] == 2, 'Expected a three dimensional input with 2 channels'\n",
    "        X = torch.from_numpy(self.input).float()\n",
    "\n",
    "        # Create a stacked representation and a zero tensor so we can use the standard Pytorch TensorDataset\n",
    "        y = torch.from_numpy(np.zeros((X.shape[0], 1))).float()\n",
    "\n",
    "        split = ShuffleSplit(n_splits=1, test_size=0.5)\n",
    "        for train_index, test_index in split.split(X):\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        train_dset = TensorDataset(X_train, y_train)\n",
    "        test_dset = TensorDataset(X_test, y_test)\n",
    "        all_dset = TensorDataset(X, y)\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        **kwargs)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=False,\n",
    "                                                       **kwargs)\n",
    "        self.all_loader = torch.utils.data.DataLoader(all_dset,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=False,\n",
    "                                                      **kwargs)\n",
    "\n",
    "    def train_vae(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse'):\n",
    "        \"\"\"\n",
    "        Handles the training of the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of complete passes over the whole training set.\n",
    "        hidden_size : int\n",
    "            Size of the latent space of the vae.\n",
    "        lr : float.\n",
    "            Learning rate for the vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        set_seed(42)  # Set the random seed\n",
    "        self.model = VAE(hidden_size,\n",
    "                         self.input.shape)  # Inititalize the model\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=lr,\n",
    "                               betas=(0.9, 0.999))\n",
    "    \n",
    "\n",
    "\n",
    "        if self.plot_loss:\n",
    "            liveloss = PlotLosses()\n",
    "            liveloss.skip_first = 0\n",
    "            liveloss.figsize = (16, 10)\n",
    "\n",
    "        # Start training loop\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            tl = train(epoch,\n",
    "                       self.model,\n",
    "                       optimizer,\n",
    "                       self.train_loader,\n",
    "                       recon_loss_method=recon_loss_method)  # Train model on train dataset\n",
    "            testl = test(epoch, self.model, self.test_loader, recon_loss_method=recon_loss_method)\n",
    "\n",
    "            if self.plot_loss:  # log train and test losses for dynamic plot\n",
    "                logs = {}\n",
    "                logs['' + 'ELBO'] = tl\n",
    "                logs['val_' + 'ELBO'] = testl\n",
    "                liveloss.update(logs)\n",
    "                liveloss.draw()\n",
    "            return testl\n",
    "\n",
    "    def run_vae(self):\n",
    "        \"\"\"\n",
    "        Run the full data set through the trained vae model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies the zs attribute, an array of shape (number_traces, latent_space)\n",
    "        \"\"\"\n",
    "        _, zs = forward_all(self.model, self.all_loader)\n",
    "        return zs.numpy()\n",
    "\n",
    "    def reduce(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse', plot_loss=True):\n",
    "        \"\"\"\n",
    "        Controller function for the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs to run vae model.\n",
    "        hidden_size : int\n",
    "            Size of the vae model latent space representation.\n",
    "        lr : float\n",
    "            Learning rate for vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "        plot_loss : bool\n",
    "            Control on whether to plot the loss on vae training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies embedding attribute via generation of the low dimensional representation.\n",
    "\n",
    "        \"\"\"\n",
    "        if hidden_size < 2:\n",
    "            raise Exception('Please use hidden size > 1')\n",
    "\n",
    "        self.plot_loss = plot_loss  # define whether to plot training losses or not\n",
    "        self.create_dataloader()\n",
    "\n",
    "        if not self.loaded_model:\n",
    "            loss = self.train_vae(epochs=epochs, hidden_size=hidden_size, lr=lr, recon_loss_method=recon_loss_method)\n",
    "\n",
    "        self.embedding = self.run_vae()  # arbitrary dimension output from VAE\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     52,
     103,
     114
    ]
   },
   "outputs": [],
   "source": [
    "class VaeModelSGDM(ModelAgent):\n",
    "    \"\"\"\n",
    "    Runs the VAE model to reduce the seismic data to an arbitrary sized dimension, visualised in 2 via UMAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.name = 'VAE'\n",
    "\n",
    "    def create_dataloader(self, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create pytorch data loaders for use in vae training, testing and running.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of data loader batches.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies object data loader attributes.\n",
    "\n",
    "        \"\"\"\n",
    "        # create torch tensor\n",
    "        assert self.input.shape[1] == 2, 'Expected a three dimensional input with 2 channels'\n",
    "        X = torch.from_numpy(self.input).float()\n",
    "\n",
    "        # Create a stacked representation and a zero tensor so we can use the standard Pytorch TensorDataset\n",
    "        y = torch.from_numpy(np.zeros((X.shape[0], 1))).float()\n",
    "\n",
    "        split = ShuffleSplit(n_splits=1, test_size=0.5)\n",
    "        for train_index, test_index in split.split(X):\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        train_dset = TensorDataset(X_train, y_train)\n",
    "        test_dset = TensorDataset(X_test, y_test)\n",
    "        all_dset = TensorDataset(X, y)\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        **kwargs)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=False,\n",
    "                                                       **kwargs)\n",
    "        self.all_loader = torch.utils.data.DataLoader(all_dset,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=False,\n",
    "                                                      **kwargs)\n",
    "\n",
    "    def train_vae(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse', momentum=0.5):\n",
    "        \"\"\"\n",
    "        Handles the training of the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of complete passes over the whole training set.\n",
    "        hidden_size : int\n",
    "            Size of the latent space of the vae.\n",
    "        lr : float.\n",
    "            Learning rate for the vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        set_seed(42)  # Set the random seed\n",
    "        self.model = VAE(hidden_size,\n",
    "                         self.input.shape)  # Inititalize the model\n",
    "        \n",
    "        optimizer = optim.SGD(self.model.parameters(), \n",
    "                              lr=lr, \n",
    "                              momentum=momentum)\n",
    "\n",
    "        if self.plot_loss:\n",
    "            liveloss = PlotLosses()\n",
    "            liveloss.skip_first = 0\n",
    "            liveloss.figsize = (16, 10)\n",
    "\n",
    "        # Start training loop\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            tl = train(epoch,\n",
    "                       self.model,\n",
    "                       optimizer,\n",
    "                       self.train_loader,\n",
    "                       recon_loss_method=recon_loss_method)  # Train model on train dataset\n",
    "            testl = test(epoch, self.model, self.test_loader, recon_loss_method=recon_loss_method)\n",
    "\n",
    "            if self.plot_loss:  # log train and test losses for dynamic plot\n",
    "                logs = {}\n",
    "                logs['' + 'ELBO'] = tl\n",
    "                logs['val_' + 'ELBO'] = testl\n",
    "                liveloss.update(logs)\n",
    "                liveloss.draw()\n",
    "        \n",
    "        return testl\n",
    "\n",
    "    def run_vae(self):\n",
    "        \"\"\"\n",
    "        Run the full data set through the trained vae model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies the zs attribute, an array of shape (number_traces, latent_space)\n",
    "        \"\"\"\n",
    "        _, zs = forward_all(self.model, self.all_loader)\n",
    "        return zs.numpy()\n",
    "\n",
    "    def reduce(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse', plot_loss=True, momentum=0.5):\n",
    "        \"\"\"\n",
    "        Controller function for the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs to run vae model.\n",
    "        hidden_size : int\n",
    "            Size of the vae model latent space representation.\n",
    "        lr : float\n",
    "            Learning rate for vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "        plot_loss : bool\n",
    "            Control on whether to plot the loss on vae training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies embedding attribute via generation of the low dimensional representation.\n",
    "\n",
    "        \"\"\"\n",
    "        if hidden_size < 2:\n",
    "            raise Exception('Please use hidden size > 1')\n",
    "\n",
    "        self.plot_loss = plot_loss  # define whether to plot training losses or not\n",
    "        self.create_dataloader()\n",
    "\n",
    "        if not self.loaded_model:\n",
    "            loss = self.train_vae(epochs=epochs, hidden_size=hidden_size, lr=lr, recon_loss_method=recon_loss_method, momentum=momentum)\n",
    "\n",
    "        self.embedding = self.run_vae()  # arbitrary dimension output from VAE\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_pi2 = open('./pickled/data.pickle', 'rb')\n",
    "dataholder = pickle.load(file_pi2)\n",
    "file_pi2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor has created an output with shape:  (25351, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "### Processor\n",
    "processor = Processor(dataholder)\n",
    "input1 = processor(flatten=[True, 12, 52], normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelAgent initialised\n",
      "ModelAgent initialised\n"
     ]
    }
   ],
   "source": [
    "vaeADAM = VaeModelADAM(input1)\n",
    "vaeSGDM = VaeModelSGDM(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO:\n",
      "training   (min:      nan, max:      nan, cur:      nan)\n",
      "validation (min:      nan, max:      nan, cur:      nan)\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.0001,0.001,0.01,0.1]\n",
    "adamlosses = []\n",
    "for i in lrs:\n",
    "    print('learningrate:', i)\n",
    "    adamloss = vaeADAM.reduce(epochs=20, hidden_size=4, lr=i, plot_loss=True)\n",
    "    print(adamloss)\n",
    "    adamlosses.append(adamlosses)\n",
    "\n",
    "plt.plot(lrs, adamlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentums = [0.01,0.1,0.2,0.4,0.6,0.8]\n",
    "sgdlosses = []\n",
    "for i in momentums:\n",
    "    print('momentum:', i)\n",
    "    sgdloss = vaeSGDM.reduce(epochs=20, hidden_size=8, lr=0.0001, plot_loss=True, momentum=i)\n",
    "    sgdlosses.append(sgdloss)\n",
    "    \n",
    "plt.plot(momentums, sgdlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
