{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SeismicReduction import *\n",
    "import pickle\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_loader, beta=1, recon_loss_method='mse'):\n",
    "    \"\"\"\n",
    "    Trains a single epoch of the vae model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int\n",
    "        epoch number being trained\n",
    "    model : torch.nn.module\n",
    "        model being trained, here a vae\n",
    "    optimizer : torch.optim\n",
    "        optmizer used to train model\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        data loader used for training\n",
    "    beta : float\n",
    "        beta parameter for the beta-vae\n",
    "    recon_loss_method : str\n",
    "        specifies the reconstruction loss technique\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trains the model and returns training loss for the epoch\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar, _ = model(data)\n",
    "        loss = loss_function(recon_batch,\n",
    "                             data,\n",
    "                             mu,\n",
    "                             logvar,\n",
    "                             window_size=data.shape[-1],\n",
    "                             beta=beta,\n",
    "                             recon_loss_method=recon_loss_method)\n",
    "        # print('batch:', batch_idx, 'loss:', loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        # 'loss' is the SUM of all vector to vector losses in batch\n",
    "        train_loss += loss.item()  # * data.size(0)  # originally\n",
    "\n",
    "#         print('batch:', batch_idx, 'to add to total:', loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    # print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss), len(train_loader.dataset))\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     1,
     45,
     65,
     86,
     94
    ]
   },
   "outputs": [],
   "source": [
    "# VAE 1 ( details: normal)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of vae.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, shape_in):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #  Architecture paramaters\n",
    "        shape = shape_in[-1]\n",
    "\n",
    "        assert shape % 4 == 0, 'input dimension for VAE must be factor of 4'\n",
    "\n",
    "        # specified reduction factor of each convolution, if layer number or stride is changed update this list!!\n",
    "        reductions = [0.5, 0.5, 0.5]\n",
    "\n",
    "        self.last_conv_channels = 34  # number of channels after last convolution\n",
    "\n",
    "        # find the resultant dimension post convolution layer processing\n",
    "        post_conv = self.post_conv_dim(shape, reductions)\n",
    "\n",
    "        self.linear_dimension = post_conv * self.last_conv_channels\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv1d(2, 3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(3, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(32, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv1d(32, self.last_conv_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(self.linear_dimension, 128)\n",
    "\n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(128, hidden_size)\n",
    "        self.fc22 = nn.Linear(128, hidden_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(hidden_size, 128)\n",
    "        self.fc4 = nn.Linear(128, self.linear_dimension)\n",
    "        self.deconv1 = nn.ConvTranspose1d(self.last_conv_channels, 32,kernel_size=4,stride=2,padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv1d(32, 2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def post_conv_dim(self, in_shape, conv_reductions):\n",
    "        \"\"\"\n",
    "        Calculates the dimension of the data at the end of convolutions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_shape : int\n",
    "            Input dimension.\n",
    "        conv_reductions : list\n",
    "            List that specifies the reduction factor for each convolution, generally 1/stride of each layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int dimension post convolutions based on input dimension.\n",
    "        \"\"\"\n",
    "        for i in conv_reductions:\n",
    "            in_shape = int(np.ceil(\n",
    "                in_shape * i))  #  calc the resultant size from each conv\n",
    "        return in_shape\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode the input into latent space variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Input data array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Latent space representation.\n",
    "        \"\"\"\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode from latent space back into input dimension.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : array_like\n",
    "            Latent space representation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Reconstructed data array.\n",
    "        \"\"\"\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        out = out.view(out.size(0), self.last_conv_channels,\n",
    "                       int(self.linear_dimension / self.last_conv_channels))\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.conv5(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        __call__ function for the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Model input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        decode : array_like\n",
    "            Reconstructed data in dimension of input.\n",
    "        mu : array_like\n",
    "            Latent space representation mean\n",
    "        logvar : array_like\n",
    "            Latent space representation variance\n",
    "        z : array_like\n",
    "            Latent space representation mean\n",
    "\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# VAE 2 ( details: small)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of vae.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, shape_in):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #  Architecture paramaters\n",
    "        shape = shape_in[-1]\n",
    "\n",
    "        assert shape % 4 == 0, 'input dimension for VAE must be factor of 4'\n",
    "\n",
    "        # specified reduction factor of each convolution, if layer number or stride is changed update this list!!\n",
    "        reductions = [0.5, 0.5, 0.5]\n",
    "\n",
    "        self.last_conv_channels = 32  # number of channels after last convolution\n",
    "\n",
    "        # find the resultant dimension post convolution layer processing\n",
    "        post_conv = self.post_conv_dim(shape, reductions)\n",
    "\n",
    "        self.linear_dimension = post_conv * self.last_conv_channels\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv1d(2, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(4, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(8, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv1d(16, self.last_conv_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(self.linear_dimension, 128)\n",
    "\n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(128, hidden_size)\n",
    "        self.fc22 = nn.Linear(128, hidden_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(hidden_size, 128)\n",
    "        self.fc4 = nn.Linear(128, self.linear_dimension)\n",
    "        self.deconv1 = nn.ConvTranspose1d(self.last_conv_channels, 32,kernel_size=4,stride=2,padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv1d(32, 2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def post_conv_dim(self, in_shape, conv_reductions):\n",
    "        \"\"\"\n",
    "        Calculates the dimension of the data at the end of convolutions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_shape : int\n",
    "            Input dimension.\n",
    "        conv_reductions : list\n",
    "            List that specifies the reduction factor for each convolution, generally 1/stride of each layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int dimension post convolutions based on input dimension.\n",
    "        \"\"\"\n",
    "        for i in conv_reductions:\n",
    "            in_shape = int(np.ceil(\n",
    "                in_shape * i))  #  calc the resultant size from each conv\n",
    "        return in_shape\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode the input into latent space variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Input data array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Latent space representation.\n",
    "        \"\"\"\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode from latent space back into input dimension.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : array_like\n",
    "            Latent space representation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Reconstructed data array.\n",
    "        \"\"\"\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        out = out.view(out.size(0), self.last_conv_channels,\n",
    "                       int(self.linear_dimension / self.last_conv_channels))\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.conv5(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        __call__ function for the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Model input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        decode : array_like\n",
    "            Reconstructed data in dimension of input.\n",
    "        mu : array_like\n",
    "            Latent space representation mean\n",
    "        logvar : array_like\n",
    "            Latent space representation variance\n",
    "        z : array_like\n",
    "            Latent space representation mean\n",
    "\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# VAE 3 ( details: large)\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch implementation of vae.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, shape_in):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        #  Architecture paramaters\n",
    "        shape = shape_in[-1]\n",
    "\n",
    "        assert shape % 4 == 0, 'input dimension for VAE must be factor of 4'\n",
    "\n",
    "        # specified reduction factor of each convolution, if layer number or stride is changed update this list!!\n",
    "        reductions = [0.5, 0.5, 0.5]\n",
    "\n",
    "        self.last_conv_channels = 128  # number of channels after last convolution\n",
    "\n",
    "        # find the resultant dimension post convolution layer processing\n",
    "        post_conv = self.post_conv_dim(shape, reductions)\n",
    "\n",
    "        self.linear_dimension = post_conv * self.last_conv_channels\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv1d(2, 4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(4, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(16, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv1d(64, self.last_conv_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(self.linear_dimension, 128)\n",
    "\n",
    "        # Latent space\n",
    "        self.fc21 = nn.Linear(128, hidden_size)\n",
    "        self.fc22 = nn.Linear(128, hidden_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(hidden_size, 128)\n",
    "        self.fc4 = nn.Linear(128, self.linear_dimension)\n",
    "        self.deconv1 = nn.ConvTranspose1d(self.last_conv_channels, 32,kernel_size=4,stride=2,padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose1d(32, 32, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv1d(32, 2, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def post_conv_dim(self, in_shape, conv_reductions):\n",
    "        \"\"\"\n",
    "        Calculates the dimension of the data at the end of convolutions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_shape : int\n",
    "            Input dimension.\n",
    "        conv_reductions : list\n",
    "            List that specifies the reduction factor for each convolution, generally 1/stride of each layer.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int dimension post convolutions based on input dimension.\n",
    "        \"\"\"\n",
    "        for i in conv_reductions:\n",
    "            in_shape = int(np.ceil(\n",
    "                in_shape * i))  #  calc the resultant size from each conv\n",
    "        return in_shape\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        Encode the input into latent space variables.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Input data array.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Latent space representation.\n",
    "        \"\"\"\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        h1 = self.relu(self.fc1(out))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        Decode from latent space back into input dimension.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : array_like\n",
    "            Latent space representation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Reconstructed data array.\n",
    "        \"\"\"\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        out = self.relu(self.fc4(h3))\n",
    "        out = out.view(out.size(0), self.last_conv_channels,\n",
    "                       int(self.linear_dimension / self.last_conv_channels))\n",
    "        out = self.relu(self.deconv1(out))\n",
    "        out = self.relu(self.deconv2(out))\n",
    "        out = self.relu(self.deconv3(out))\n",
    "        out = self.conv5(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        __call__ function for the class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array_like\n",
    "            Model input data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        decode : array_like\n",
    "            Reconstructed data in dimension of input.\n",
    "        mu : array_like\n",
    "            Latent space representation mean\n",
    "        logvar : array_like\n",
    "            Latent space representation variance\n",
    "        z : array_like\n",
    "            Latent space representation mean\n",
    "\n",
    "        \"\"\"\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     102,
     113
    ]
   },
   "outputs": [],
   "source": [
    "class VaeModel(ModelAgent):\n",
    "    \"\"\"\n",
    "    Runs the VAE model to reduce the seismic data to an arbitrary sized dimension, visualised in 2 via UMAP.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.name = 'VAE'\n",
    "\n",
    "    def create_dataloader(self, test_size=0.5, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create pytorch data loaders for use in vae training, testing and running.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of data loader batches.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies object data loader attributes.\n",
    "\n",
    "        \"\"\"\n",
    "        # create torch tensor\n",
    "        assert self.input.shape[1] == 2, 'Expected a three dimensional input with 2 channels'\n",
    "        X = torch.from_numpy(self.input).float()\n",
    "\n",
    "        # Create a stacked representation and a zero tensor so we can use the standard Pytorch TensorDataset\n",
    "        y = torch.from_numpy(np.zeros((X.shape[0], 1))).float()\n",
    "\n",
    "        split = ShuffleSplit(n_splits=1, test_size=test_size)\n",
    "        for train_index, test_index in split.split(X):\n",
    "            X_train, y_train = X[train_index], y[train_index]\n",
    "            X_test, y_test = X[test_index], y[test_index]\n",
    "\n",
    "        train_dset = TensorDataset(X_train, y_train)\n",
    "        test_dset = TensorDataset(X_test, y_test)\n",
    "        all_dset = TensorDataset(X, y)\n",
    "\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_dset,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        **kwargs)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_dset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=False,\n",
    "                                                       **kwargs)\n",
    "        self.all_loader = torch.utils.data.DataLoader(all_dset,\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      shuffle=False,\n",
    "                                                      **kwargs)\n",
    "\n",
    "    def train_vae(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse'):\n",
    "        \"\"\"\n",
    "        Handles the training of the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of complete passes over the whole training set.\n",
    "        hidden_size : int\n",
    "            Size of the latent space of the vae.\n",
    "        lr : float.\n",
    "            Learning rate for the vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        \"\"\"\n",
    "        set_seed(42)  # Set the random seed\n",
    "        self.model = VAE(hidden_size,\n",
    "                         self.input.shape)  # Inititalize the model\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=lr,\n",
    "                               betas=(0.9, 0.999))\n",
    "    \n",
    "\n",
    "\n",
    "        if self.plot_loss:\n",
    "            liveloss = PlotLosses()\n",
    "            liveloss.skip_first = 0\n",
    "            liveloss.figsize = (16, 10)\n",
    "\n",
    "        # Start training loop\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            tl = train(epoch, self.model, optimizer, self.train_loader, recon_loss_method=recon_loss_method)  # Train model on train dataset\n",
    "            \n",
    "            testl = test(epoch, self.model, self.test_loader, recon_loss_method=recon_loss_method)\n",
    "\n",
    "            if self.plot_loss:  # log train and test losses for dynamic plot\n",
    "                logs = {}\n",
    "                logs['' + 'ELBO'] = tl\n",
    "                logs['val_' + 'ELBO'] = testl\n",
    "                liveloss.update(logs)\n",
    "                liveloss.draw()\n",
    "                \n",
    "        return testl\n",
    "\n",
    "    def run_vae(self):\n",
    "        \"\"\"\n",
    "        Run the full data set through the trained vae model.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies the zs attribute, an array of shape (number_traces, latent_space)\n",
    "        \"\"\"\n",
    "        _, zs = forward_all(self.model, self.all_loader)\n",
    "        return zs.numpy()\n",
    "\n",
    "    def reduce(self, epochs=5, hidden_size=8, lr=1e-2, recon_loss_method='mse', plot_loss=True, test_size=0.5):\n",
    "        \"\"\"\n",
    "        Controller function for the vae model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs to run vae model.\n",
    "        hidden_size : int\n",
    "            Size of the vae model latent space representation.\n",
    "        lr : float\n",
    "            Learning rate for vae model training.\n",
    "        recon_loss_method : str\n",
    "            Method for reconstruction loss calculation\n",
    "        plot_loss : bool\n",
    "            Control on whether to plot the loss on vae training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Modifies embedding attribute via generation of the low dimensional representation.\n",
    "\n",
    "        \"\"\"\n",
    "        if hidden_size < 2:\n",
    "            raise Exception('Please use hidden size > 1')\n",
    "\n",
    "        self.plot_loss = plot_loss  # define whether to plot training losses or not\n",
    "        self.create_dataloader(test_size=test_size)\n",
    "\n",
    "        if not self.loaded_model:\n",
    "            loss = self.train_vae(epochs=epochs, hidden_size=hidden_size, lr=lr, recon_loss_method=recon_loss_method)\n",
    "\n",
    "        self.embedding = self.run_vae()  # arbitrary dimension output from VAE\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file_pi2 = open('./pickled/data.pickle', 'rb')\n",
    "dataholder = pickle.load(file_pi2)\n",
    "file_pi2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor has created an output with shape:  (25351, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "### Processor\n",
    "processor = Processor(dataholder)\n",
    "input1 = processor(flatten=[True, 12, 52], normalise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelAgent initialised\n"
     ]
    }
   ],
   "source": [
    "vae = VaeModel(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
